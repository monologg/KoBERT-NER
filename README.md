# KoBERT-NER

- KoBERTë¥¼ ì´ìš©í•œ í•œêµ­ì–´ Named Entity Recognition Task
- ğŸ¤—`Huggingface Tranformers`ğŸ¤— ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ êµ¬í˜„

## Dependencies

- torch==1.4.0
- transformers==2.10.0
- seqeval>=0.0.12

## Dataset

- **Naver NLP Challenge 2018**ì˜ NER Dataset ì‚¬ìš© ([Github link](https://github.com/naver/nlp-challenge))
- í•´ë‹¹ ë°ì´í„°ì…‹ì— Train datasetë§Œ ì¡´ì¬í•˜ê¸°ì—, Test datasetì€ Train datasetì—ì„œ splití•˜ì˜€ìŠµë‹ˆë‹¤. ([Data link](https://github.com/aisolab/nlp_implementation/tree/master/Bidirectional_LSTM-CRF_Models_for_Sequence_Tagging/data))
  - Train (81,000) / Test (9,000)

## How to use KoBERT on Huggingface Transformers Library

- ê¸°ì¡´ì˜ KoBERTë¥¼ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ê³§ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë§ì·„ìŠµë‹ˆë‹¤.
  - transformers v2.2.2ë¶€í„° ê°œì¸ì´ ë§Œë“  ëª¨ë¸ì„ transformersë¥¼ í†µí•´ ì§ì ‘ ì—…ë¡œë“œ/ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- Tokenizerë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ `tokenization_kobert.py`ì—ì„œ `KoBertTokenizer`ë¥¼ ì„í¬íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤.

```python
from transformers import BertModel
from tokenization_kobert import KoBertTokenizer

model = BertModel.from_pretrained('monologg/kobert')
tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')
```

## Usage

```bash
$ python3 main.py --model_type kobert --do_train --do_eval
```

- `--write_pred` ì˜µì…˜ì„ ì£¼ë©´ **evaluationì˜ prediction ê²°ê³¼**ê°€ `preds` í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.

## Prediction

```bash
$ python3 predict.py --input_file {INPUT_FILE_PATH} --output_file {OUTPUT_FILE_PATH} --model_dir {SAVED_CKPT_PATH}
```

## Results

|                                                                  | Slot F1 (%) |
| ---------------------------------------------------------------- | ----------- |
| KoBERT                                                           | 86.11       |
| DistilKoBERT                                                     | 84.13       |
| Bert-Multilingual                                                | 84.20       |
| [CNN-BiLSTM-CRF](https://github.com/monologg/korean-ner-pytorch) | 74.57       |

## References

- [Naver NLP Challenge](https://github.com/naver/nlp-challenge)
- [Huggingface Transformers](https://github.com/huggingface/transformers)
- [NLP Implementation by aisolab](https://github.com/aisolab/nlp_implementation)
- [BERT NER by eagle705](https://github.com/eagle705/pytorch-bert-crf-ner)
